{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujithk\\AppData\\Local\\Continuum\\anaconda3\\envs\\Virtual_Env\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# from string import maketrans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import re\n",
    "import ftfy as ft\n",
    "import time\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from scipy.sparse import csr_matrix\n",
    "import sparse_dot_topn.sparse_dot_topn as ct\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "t=open(r\"C:\\dev\\personal\\Web Scraping\\projects\\tesco\\tesco_072720.json\")\n",
    "a=open(r\"C:\\dev\\personal\\Web Scraping\\projects\\asda\\asda_072720.json\")\n",
    "s=open(r\"C:\\dev\\personal\\Web Scraping\\projects\\sainsburys\\sainsburys_072720.json\")\n",
    "w=open(r\"C:\\dev\\personal\\Web Scraping\\projects\\waitrose\\waitrose_072720.json\")\n",
    "m=open(r\"C:\\dev\\personal\\Web Scraping\\projects\\morrisons\\morrisons_072720.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesco_price=json.load(t)\n",
    "# print(tesco_price)\n",
    "ctr=1\n",
    "tesco_prod_name=[]\n",
    "for i in tesco_price:\n",
    "    tesco_prod_name.insert(ctr,i['tesco_prod_name'])\n",
    "    ctr+=1\n",
    "\n",
    "#print(tesco_prod_name)\n",
    "t.close()\n",
    "\n",
    "asda_price=json.load(a)\n",
    "# print(asda_price)\n",
    "ctr=1\n",
    "asda_prod_name=[]\n",
    "for i in asda_price:\n",
    "    asda_prod_name.insert(ctr,i['asda_prod_name'])\n",
    "    ctr+=1\n",
    "\n",
    "#print(asda_prod_name)\n",
    "a.close()\n",
    "\n",
    "morrisons_price=json.load(m)\n",
    "# print(morrisons_price)\n",
    "ctr=1\n",
    "morrisons_prod_name=[]\n",
    "for i in morrisons_price:\n",
    "    morrisons_prod_name.insert(ctr,i['morrisons_prod_name'])\n",
    "    ctr+=1\n",
    "\n",
    "#print(morrisons_prod_name)\n",
    "m.close()\n",
    "\n",
    "waitrose_price=json.load(w)\n",
    "# print(waitrose_price)\n",
    "ctr=1\n",
    "waitrose_prod_name=[]\n",
    "for i in waitrose_price:\n",
    "    waitrose_prod_name.insert(ctr,i['waitrose_prod_name'])\n",
    "    ctr+=1\n",
    "\n",
    "#print(waitrose_prod_name)\n",
    "w.close()\n",
    "\n",
    "sainsburys_price=json.load(s)\n",
    "# print(sainsburys_price)\n",
    "ctr=1\n",
    "sainsburys_prod_name=[]\n",
    "for i in sainsburys_price:\n",
    "    sainsburys_prod_name.insert(ctr,i['sainsburys_prod_name'])\n",
    "    ctr+=1\n",
    "\n",
    "#print(sainsburys_prod_name)\n",
    "s.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tesco pre deduping\n",
      "204\n",
      "Shape and count of tesco post deduping\n",
      "204\n",
      "Shape of asda pre deduping\n",
      "248\n",
      "Shape and count of asda post deduping\n",
      "61\n",
      "Shape of morrisons pre deduping\n",
      "340\n",
      "Shape and count of morrisons post deduping\n",
      "340\n",
      "Shape of sainsburys pre deduping\n",
      "179\n",
      "Shape and count of sainsburys post deduping\n",
      "179\n",
      "Shape of waitrose pre deduping\n",
      "135\n",
      "Shape and count of waitrose post deduping\n",
      "135\n"
     ]
    }
   ],
   "source": [
    "def uniq(list1):\n",
    "    list_set=set(list1)\n",
    "    unique_list=list(list_set)\n",
    "    return unique_list\n",
    "\n",
    "tesco_prod_name_uniq=np.array(uniq(tesco_prod_name))\n",
    "asda_prod_name_uniq=np.array(uniq(asda_prod_name))\n",
    "morrisons_prod_name_uniq=np.array(uniq(morrisons_prod_name))\n",
    "sainsburys_prod_name_uniq=np.array(uniq(sainsburys_prod_name))\n",
    "waitrose_prod_name_uniq=np.array(uniq(waitrose_prod_name))\n",
    "\n",
    "prim_vec_count=len(tesco_prod_name_uniq)\n",
    "morrisons_trg_vec_count=len(morrisons_prod_name_uniq)\n",
    "waitrose_trg_vec_count=len(waitrose_prod_name_uniq)\n",
    "sainsburys_trg_vec_count=len(sainsburys_prod_name_uniq)\n",
    "asda_trg_vec_count=len(asda_prod_name_uniq)\n",
    "\n",
    "\n",
    "print(\"Shape of tesco pre deduping\")\n",
    "print(len(tesco_prod_name))\n",
    "print(\"Shape and count of tesco post deduping\")\n",
    "print(prim_vec_count)\n",
    "\n",
    "print(\"Shape of asda pre deduping\")\n",
    "print(len(asda_prod_name))\n",
    "print(\"Shape and count of asda post deduping\")\n",
    "print(asda_trg_vec_count)\n",
    "\n",
    "print(\"Shape of morrisons pre deduping\")\n",
    "print(len(morrisons_prod_name))\n",
    "print(\"Shape and count of morrisons post deduping\")\n",
    "print(morrisons_trg_vec_count)\n",
    "\n",
    "print(\"Shape of sainsburys pre deduping\")\n",
    "print(len(sainsburys_prod_name))\n",
    "print(\"Shape and count of sainsburys post deduping\")\n",
    "print(sainsburys_trg_vec_count)\n",
    "\n",
    "print(\"Shape of waitrose pre deduping\")\n",
    "print(len(waitrose_prod_name))\n",
    "print(\"Shape and count of waitrose post deduping\")\n",
    "print(waitrose_trg_vec_count)\n",
    "\n",
    "\n",
    "#test_vector=np.array(tesco_prod_name_uniq+morrisons_prod_name_uniq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lorealelviveextraordinaryoilshampoodryhair250\n",
      " 250\n",
      "004aaaabbceeeeeeghhilmnnnoooprrrssssw\n",
      "004aaabbcccdeeeeeeehhhiikllmmnnnoooooprrrssssttuwy\n",
      "004aaaabbccceeeeeefghhiillmmnnnooooooooprrrrssssw\n",
      "035aaaaabbeehlllmmoooppprsst\n",
      "['Alberto Balsam Tea Tree Tingle Conditioner  350ml'\n",
      " 'Alberto Balsam Juicy Green Apple Conditioner  350ml'\n",
      " 'Alberto Balsam Raspberry Shampoo 350ml'\n",
      " 'Alberto Balsam Restore Shampoo 250ml'\n",
      " 'Alberto Balsam Energize Conditioner 250ml'\n",
      " 'Alberto Balsam Energize Shampoo 250ml'\n",
      " 'Alberto Balsam Coconut & Lychee Nourishing Shampoo 350ml'\n",
      " 'Alberto Balsam Tea Tree Tingle Shampoo  350ml'\n",
      " 'Alberto Balsam Juicy Green Apple Shampoo  350ml'\n",
      " 'Alberto Balsam Raspberry Conditioner 350ml'\n",
      " 'Alberto Balsam Coconut & Lychee Conditioner  350ml'\n",
      " 'Alberto Balsam Restore Conditioner 250ml']\n",
      "albertobalsamraspberryshampoo350\n",
      "Alberto Balsam Raspberry Shampoo 350ml\n"
     ]
    }
   ],
   "source": [
    "frtoeng = \"\".maketrans(\"àâçéèêîôùû\", \"aaceeeiouu\")\n",
    "\n",
    "def cleanup(string):\n",
    "    string = ft.fix_text(string) # fix text encoding issues\n",
    "    string = string.translate(frtoeng)\n",
    "    string = string.encode(\"ascii\", errors=\"ignore\").decode() #remove non ascii chars\n",
    "    string = string.lower() #make lower case\n",
    "    chars_to_remove = [\")\",\"(\",\".\",\"|\",\"[\",\"]\",\"{\",\"}\",\"'\",\" \"]\n",
    "    rx = '[' + re.escape(''.join(chars_to_remove)) + ']'\n",
    "    string = re.sub(rx, '', string) #remove the list of chars defined above\n",
    "    string = string.replace('&', '')\n",
    "    string = string.replace('and', '')\n",
    "    string = string.replace('ml', '')\n",
    "    string = string.replace('Ml', 'ml')\n",
    "    string = string.replace(',', '')\n",
    "    string = string.replace('-', '')\n",
    "    #string=\"\".join(sorted(string))\n",
    "    #string = string.replace('shampoo', '')\n",
    "    #string = string.title() # normalise case - capital at start of each word\n",
    "    string = re.sub(' +',' ',string).strip() # get rid of multiple spaces and replace with a single space\n",
    "    # string = ' '+ string +' ' # pad names for ngrams...\n",
    "    string = re.sub(r'[,-./]|\\sBD',r'', string)\n",
    "    return string\n",
    "\n",
    "f= lambda x: cleanup(x)\n",
    "morrisons_prod_name_uniq_cleaned= np.array([f(xi) for xi in morrisons_prod_name_uniq])\n",
    "waitrose_prod_name_uniq_cleaned= np.array([f(xi) for xi in waitrose_prod_name_uniq])\n",
    "sainsburys_prod_name_uniq_cleaned= np.array([f(xi) for xi in sainsburys_prod_name_uniq])\n",
    "\n",
    "\n",
    "#Test Cases\n",
    "## Case I\n",
    "print(cleanup(\"L'OrÃƒÂ©al Elvive Extraordinary Oil Shampoo Dry Hair  250ml\"))\n",
    "print(\"L'OrÃƒÂ©al Elvive Extraordinary Oil Shampoo Dry Hair  250ml\"[\"L'OrÃƒÂ©al Elvive Extraordinary Oil Shampoo Dry Hair  250ml\".rstrip().rfind(\" \"):-2])\n",
    "j=\"L'OrÃƒÂ©al Elvive Extraordinary Oil Shampoo Dry Hair  250ml\"[\"L'OrÃƒÂ©al Elvive Extraordinary Oil Shampoo Dry Hair  250ml\".rstrip().rfind(\" \"):-2]\n",
    "\n",
    "## Case II\n",
    "\n",
    "print(\"\".join(sorted(cleanup(\"Herbal Essences Bio. Renew Argan Shampoo 400Ml\"))))\n",
    "print(\"\".join(sorted(cleanup(\"Herbal Essences Bio Renew Shampoo Coconut Milk Hydrate 400ml\"))))\n",
    "print(\"\".join(sorted(cleanup(\"Herbal Essences Bio Renew Shampoo Argan Oil of Morocco 400ml\")))) #ideally this one should be selected as the right match\n",
    "\n",
    "\n",
    "## Case III\n",
    "\n",
    "\n",
    "print(\"\".join(sorted(cleanup(\"Alberto Balsam Apple Shampoo 350Ml\"))))\n",
    "\n",
    "k=[x for x in morrisons_prod_name if x.find(\"Alberto Balsam\")!=-1]\n",
    "l=np.array(uniq(k))\n",
    "print(l)\n",
    "ratio = process.extract(cleanup(\"Alberto Balsam Apple Shampoo 350Ml\"), morrisons_prod_name_uniq_cleaned, limit=1, scorer=fuzz.partial_token_set_ratio)\n",
    "print(ratio[0][0])\n",
    "res=np.where(morrisons_prod_name_uniq_cleaned==ratio[0][0])\n",
    "print(morrisons_prod_name_uniq[res[0][0]])\n",
    "# k=np.array([x for x in morrisons_prod_name if x.find(j)!=-1])\n",
    "# print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matched_prod = []\n",
    "similarity = []\n",
    "\n",
    "\n",
    "# print(morrisons_prod_name_uniq_cleaned)\n",
    "for i in tesco_prod_name_uniq:\n",
    "        i1=cleanup(i)\n",
    "        j=i[i.rstrip().rfind(\" \"):-2]\n",
    "        k=[x for x in morrisons_prod_name if x.find(j)!=-1]\n",
    "        l=np.array(uniq(k))\n",
    "        if l.size==0:\n",
    "            ratio = process.extract( i1, morrisons_prod_name_uniq_cleaned, limit=1, scorer=fuzz.partial_token_sort_ratio)\n",
    "            similarity.append(0)\n",
    "        else:\n",
    "            m=np.array([f(xi) for xi in l])\n",
    "            ratio = process.extract( i1, m, limit=1)\n",
    "            similarity.append(ratio[0][1])\n",
    "        res=np.where(morrisons_prod_name_uniq_cleaned==ratio[0][0])\n",
    "        matched_prod.append(morrisons_prod_name_uniq[res[0][0]])\n",
    "        \n",
    "match = pd.DataFrame({'tesco_prod_name':tesco_prod_name_uniq, 'morrisons_prod_name':matched_prod,'similarity':similarity}) \n",
    "\n",
    "#print(match.head(1))\n",
    "match.to_csv('C:/Users/sujithk/Desktop/file1_name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_matches_df(sparse_matrix, name_vector, top=0):\n",
    "    non_zeros = sparse_matrix.nonzero()\n",
    "    \n",
    "    sparserows = non_zeros[0]\n",
    "    sparsecols = non_zeros[1]\n",
    "    \n",
    "    if top!= 0:\n",
    "        nr_matches = top\n",
    "    else:\n",
    "        nr_matches = sparsecols.size\n",
    "    print(sparsecols)\n",
    "    print(sparserows.size)\n",
    "    Tesco = np.empty([nr_matches], dtype=object) # returns a matrix of given shape\n",
    "    right_side = np.empty([nr_matches], dtype=object) # returns a matrix of given shape\n",
    "    similairity = np.zeros(nr_matches) # returns a matrix of given shape with zeros\n",
    "    i=0\n",
    "    for index in range(0, nr_matches-1):\n",
    "        if (sparserows[index] < prim_vec_count) and (sparsecols[index] >= prim_vec_count):\n",
    "            Tesco[i] = name_vector[sparserows[index]]\n",
    "            right_side[i] = name_vector[sparsecols[index]]\n",
    "            similairity[i] = sparse_matrix.data[index]\n",
    "            i=i+1\n",
    "            \n",
    "\n",
    "    \n",
    "    return pd.DataFrame({'Tesco': Tesco,\n",
    "                          'right_side': right_side,\n",
    "                           'similairity': similairity})\n",
    "\n",
    "matches_df = get_matches_df(matches, test_vector)\n",
    "matches_df.dropna(subset = [\"Tesco\"], inplace=True)\n",
    "print(matches_df.shape)\n",
    "# print(matches_df.head(100))\n",
    "matches_df= matches_df.groupby([\"Tesco\"]).apply(lambda x: x.sort_values([\"similairity\"], ascending = False)).reset_index(drop=True)\n",
    "print(matches_df)\n",
    "matches_df=matches_df.groupby([\"Tesco\"]).head(1)\n",
    "matches_df.to_csv('C:/Users/sujithk/Desktop/file_name.csv')\n",
    "# print(matches_df.sort_values(['similairity'], ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
